GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
<class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.
Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.09s/it]
Loading dataset: 100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.79s/it]
[rank: 0] Global seed set to 42
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------
You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2023-03-30 13:36:51,714 - Added key: store_based_barrier_key:1 to store for rank: 0
2023-03-30 13:36:51,715 - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
  | Name          | Type     | Params
-------------------------------------------
0 | net           | UNETR    | 73.8 M
1 | loss_function | DiceLoss | 0
-------------------------------------------
73.8 M    Trainable params
0         Non-trainable params
73.8 M    Total params
295.318   Total estimated model params size (MB)
single channel prediction, `softmax=True` ignored.
single channel prediction, `to_onehot_y=True` ignored.
single channel prediction, `include_background=False` ignored.
y_pred should be a binarized tensor.
y should be a binarized tensor.
Traceback (most recent call last):
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/trainer/call.py", line 36, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 88, in launch
    return function(*args, **kwargs)
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1112, in _run
    results = self._run_stage()
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1191, in _run_stage
    self._run_train()
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1204, in _run_train
    self._run_sanity_check()
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1276, in _run_sanity_check
    val_loop.run()
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 152, in advance
    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 137, in advance
    output = self._evaluation_step(**kwargs)
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 234, in _evaluation_step
    output = self.trainer._call_strategy_hook(hook_name, *kwargs.values())
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1494, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/strategies/ddp.py", line 359, in validation_step
    return self.model(*args, **kwargs)
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/overrides/base.py", line 110, in forward
    return self._forward_module.validation_step(*inputs, **kwargs)
  File "/home/GRAMES.POLYMTL.CA/lobouz/github/contrast-agnostic-softseg-spinalcord/monai_main.py", line 178, in validation_step
    self.forward, padding_mode="reflect")
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/monai/inferers/utils.py", line 167, in sliding_window_inference
    min_non_zero = max(importance_map_[importance_map_ != 0].min().item(), 1e-3)
RuntimeError: numel: integer multiplication overflow
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/GRAMES.POLYMTL.CA/lobouz/github/contrast-agnostic-softseg-spinalcord/monai_main.py", line 421, in <module>
    main(args)
  File "/home/GRAMES.POLYMTL.CA/lobouz/github/contrast-agnostic-softseg-spinalcord/monai_main.py", line 310, in main
    trainer.fit(pl_model)
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 609, in fit
    self, self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/trainer/call.py", line 63, in _call_and_handle_interrupt
    trainer._teardown()
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1175, in _teardown
    self.strategy.teardown()
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/strategies/ddp.py", line 490, in teardown
    super().teardown()
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/strategies/parallel.py", line 125, in teardown
    super().teardown()
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/strategies/strategy.py", line 499, in teardown
    self.accelerator.teardown()
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/pytorch_lightning/accelerators/cuda.py", line 77, in teardown
    torch.cuda.empty_cache()
  File "/home/GRAMES.POLYMTL.CA/lobouz/miniconda3/envs/monai-env/lib/python3.7/site-packages/torch/cuda/memory.py", line 125, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.